# 250615_ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation

---
**论文信息**

- **标题**: ScaleRTL: Scaling LLMs with Reasoning Data and Test-Time Compute for Accurate RTL Code Generation
- **arXiv ID**: 2506.05566
- **作者**: Authors:Chenhui Deng, Yun-Da Tsai, Guan-Ting Liu, Zhongzhi Yu, Haoxing Ren
- **发表日期**: 2025-06-05T20:24:58+00:00
- **论文链接**: [2506.05566](https://arxiv.org/abs/2506.05566)
- **总结生成时间**: 2025-06-15 19:24:22

---

**一句话概要**  
ScaleRTL通过构建大规模RTL推理数据集与测试时计算扩展策略，显著提升了大型语言模型在硬件描述代码生成任务中的性能。

**主体**  
当前大型语言模型在通用软件编码任务中已接近人类水平，但在寄存器传输级（RTL）代码生成领域仍面临关键挑战：高质量训练数据的稀缺性导致模型难以捕捉硬件设计的复杂逻辑。以往研究虽尝试对模型进行微调，但受限于非推理性质的数据集和静态推理模式，无法突破数据瓶颈与实时优化能力的天花板。

针对这一双重困境，作者提出ScaleRTL框架，其创新性体现在数据构建与推理机制两个维度。研究团队首先构建了包含3.5B标记的链式思维推理数据集，每条数据平均长达56K标记，系统覆盖了时钟同步、状态机设计等RTL核心知识。基于该数据集微调的模型展现出深度硬件推理能力。更关键的是，研究引入动态测试时计算扩展策略，通过迭代式自我反思机制，使模型能够实时检测并修正推理过程中的错误，例如在生成Verilog代码时自动调整信号位宽或优化时序路径。

实验验证表明，该方法在VerilogEval和RTLLM两个基准测试中分别以18.4%和12.7%的优势超越18个基线模型。可视化分析显示，测试时计算扩展策略能使模型在关键节点（如有限状态机设计）的准确率提升23%，且错误修正次数与最终性能呈显著正相关。这一成果不仅填补了LLM在硬件设计自动化领域的性能空白，其动态推理框架也为其他领域专用代码生成任务提供了可迁移的方法论。

**最后一句**  
该研究开创的"数据+计算"双扩展范式，为突破领域受限场景下大模型性能瓶颈提供了可复用的技术路径。