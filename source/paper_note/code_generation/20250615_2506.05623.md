# 250615_Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework

---
**论文信息**

- **标题**: Deployability-Centric Infrastructure-as-Code Generation: An LLM-based Iterative Framework
- **arXiv ID**: 2506.05623
- **作者**: Authors:Tianyi Zhang, Shidong Pan, Zejun Zhang, Zhenchang Xing, Xiaoyu Sun
- **发表日期**: 2025-06-05T22:53:12+00:00
- **论文链接**: [2506.05623](https://arxiv.org/abs/2506.05623)
- **总结生成时间**: 2025-06-15 19:24:22

---

**一句话概要**  
该研究通过提出基于大语言模型的迭代框架IaCGen和可部署性评估基准DPIaC-Eval，显著提升了基础设施即代码（IaC）模板的生成质量，将部署成功率从不足30%提升至98%，同时揭示了用户意图对齐与安全合规性等亟待解决的挑战。

**主体**  
当前基础设施即代码（IaC）生成领域存在一个关键矛盾：尽管大语言模型（LLM）能够将自然语言描述转化为代码模板，但现有研究过度关注语法正确性，而忽视了可部署性这一核心指标。作者指出，像Claude-3.5等先进模型的首轮部署成功率仅为30%左右，这种"纸上谈兵"式的评估严重制约了IaC在实际生产环境中的应用价值。

为解决这一问题，研究团队构建了一个双管齐下的解决方案。技术层面提出的IaCGen框架创新性地引入迭代反馈机制，通过多轮部署测试生成的错误信息动态优化LLM输出；评估层面则建立了包含153个真实场景的DPIaC-Eval基准，首次实现对语法、部署、用户意图和安全性的四维量化评估。实验数据显示，经过25次迭代优化后，所有测试模型的部署成功率均突破90%，其中Claude-3.5更是达到98%的惊人水平，验证了迭代机制对提升可部署性的决定性作用。

然而，亮眼数据背后仍存在显著短板。在用户意图准确率（25.2%）和安全合规通过率（8.4%）两个维度上，现有技术表现堪忧。特别是安全评估中暴露的配置漏洞，反映出LLM在理解基础设施隐性约束方面的局限性。这些发现为后续研究指明了方向——需要在语义理解与领域知识融合方面实现突破。

**最后一句**  
这项研究不仅重新定义了IaC生成的评估范式，其揭示的技术瓶颈也将推动AI驱动的基础设施自动化向安全可信、意图感知的更高阶段演进。