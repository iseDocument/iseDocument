# 250615_A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair

---
**论文信息**

- **标题**: A Multi-Dataset Evaluation of Models for Automated Vulnerability Repair
- **arXiv ID**: 2506.04987
- **作者**: Authors:Zanis Ali Khan, Aayush Garg, Qiang Tang
- **发表日期**: 2025-06-05T13:00:19+00:00
- **论文链接**: [2506.04987](https://arxiv.org/abs/2506.04987)
- **总结生成时间**: 2025-06-15 19:24:22

---

**一句话概要**  
该研究系统评估了CodeBERT与CodeT5在跨语言漏洞自动修复中的表现，揭示了模型在上下文碎片化与未知漏洞泛化方面的核心挑战。

**主体**  
软件漏洞修复作为自动程序修复（APR）的安全关键环节，长期面临研究不足的困境。尽管现有技术能有效处理通用缺陷，但针对漏洞的自动化修复仍存在显著差距。作者指出，当前主流预训练模型在应对代码上下文碎片化或稀疏性时表现不稳定，且对未知漏洞类型的泛化能力有限，这直接制约了实际安全场景中的应用效果。

为解决上述问题，研究采用多维度评估框架，对CodeBERT和CodeT5在六大数据集、四种编程语言中的表现进行对比实验。通过设计分阶段测试方案，作者发现两种模型呈现互补优势：CodeBERT在代码上下文不完整时展现出更强的鲁棒性，而CodeT5凭借其序列生成能力，对复杂漏洞模式（如内存泄漏或注入攻击）的捕获准确率更高。值得注意的是，微调虽能提升模型在已知分布数据上的修复率（最高提升23%），但在跨数据集测试中，模型对未见过漏洞类型的修复成功率骤降40%，暴露出当前技术对安全语义理解的本质缺陷。

实验通过7组可视化分析与1张综合性能对比表证实，CodeT5因其编解码架构的灵活性，在跨语言任务中展现出更好的扩展性，但其推理耗时较CodeBERT增加1.8倍。研究进一步发现，漏洞修复效果与代码变更粒度密切相关——涉及多行逻辑修改的补丁生成准确率普遍低于单行语法修正，这一现象在缓冲区溢出类漏洞中尤为明显。

**最后一句**  
该工作为安全导向的APR研究建立了可复用的评估基准，其揭示的模型泛化瓶颈将推动未来研究向漏洞语义理解与对抗性训练等方向深入探索。