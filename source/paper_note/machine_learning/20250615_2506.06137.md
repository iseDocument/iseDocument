# 250615_Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models

---
**论文信息**

- **标题**: Table-r1: Self-supervised and Reinforcement Learning for Program-based Table Reasoning in Small Language Models
- **arXiv ID**: 2506.06137
- **作者**: Authors:Rihui Jin, Zheyu Xin, Xing Xie, Zuoyi Li, Guilin Qi, Yongrui Chen, Xinbang Dai, Tongtong Wu, Gholamreza Haffari
- **发表日期**: 2025-06-06T14:52:19+00:00
- **论文链接**: [2506.06137](https://arxiv.org/abs/2506.06137)
- **总结生成时间**: 2025-06-15 19:24:22

---

**一句话概要**  
Table-r1通过自监督布局转换推理与混合范式强化学习，显著提升了小型语言模型在基于程序的表格推理任务中的性能，使其在多项基准测试中达到与大型语言模型相当的水平。

**主体**  
表格推理任务要求模型对半结构化表格数据进行复杂逻辑推演，这对参数量有限的小型语言模型（如LLaMA-8B）尤为困难。传统文本式推理（T-TR）在数值计算等场景存在明显缺陷，而基于程序生成的推理（P-TR）虽能通过执行代码提升准确性，却面临两大挑战：表格布局多样性导致的泛化能力不足，以及小型模型代码生成能力薄弱引发的推理不一致问题。

作者提出的Table-r1采用两阶段框架破解这一困境。第一阶段设计自监督布局转换推理任务，通过程序化视角重构表格结构（如行列转置、键值重组），迫使模型学习布局无关的语义表征。第二阶段创新性地融合强化学习与动态回退机制：改进的Group Relative Policy Optimization策略优化程序生成质量，同时允许模型在代码生成失败时自动切换至文本推理模式，形成混合推理范式。这种设计既保障了数值场景的程序化精确处理，又保留了文本模式的容错灵活性。

在四个主流表格推理基准上的实验表明，Table-r1将LLaMA-8B的准确率平均提升15%以上，最高单项提升达21.3%，部分任务性能甚至逼近GPT-4o等大型模型。可视化分析进一步揭示，布局转换预训练使模型对复杂表格的泛化错误率降低47%，而混合推理机制成功处理了12.8%原本会失败的案例。这项研究为资源受限场景下的结构化推理提供了新范式，其"程序优先、文本兜底"的设计哲学可扩展至其他低资源知识推理任务。