# 250617_IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents

---
**论文信息**

- **标题**: IntenTest: Stress Testing for Intent Integrity in API-Calling LLM Agents
- **arXiv ID**: 2506.07524
- **作者**: Authors:Shiwei Feng, Xiangzhe Xu, Xuan Chen, Kaiyuan Zhang, Syed Yusuf Ahmed, Zian Su, Mingwei Zheng, Xiangyu Zhang
- **发表日期**: 2025-06-09T08:09:08+00:00
- **论文链接**: [2506.07524](https://arxiv.org/abs/2506.07524)
- **总结生成时间**: 2025-06-17 19:26:49

---

**一句话概要**  
IntenTest通过API文档驱动的语义分区与智能变异策略，系统化检测调用API的LLM智能体在自然语言指令下的意图完整性偏差，显著提升错误发现率与查询效率。

**主体**  
随着LLM智能体通过自然语言调用API实现任务自动化，其核心痛点在于外部工具包迭代时容易曲解用户意图，导致执行动作偏离原始目标。传统软件测试方法依赖结构化输入，难以应对自然语言的模糊性，而现有基准测试又局限于固定用例或对抗样本，缺乏对真实场景中语义漂移的系统化检测。作者指出这一空白领域的关键在于如何构建既保留用户意图本质、又能暴露智能体理解偏差的测试用例。

为解决该问题，研究团队提出IntenTest框架，其创新性体现在三个层面：首先基于工具包API文档构建语义分区，将自然语言任务按参数类型和等价类归入不同逻辑组，形成结构化测试空间；其次设计轻量级预测器对种子任务进行定向变异，通过扰动API参数生成保留核心意图但可能触发错误的任务变体；最后引入数据类型感知的策略记忆库，动态复用历史有效的变异模式以提升效率。这种组合策略使得测试过程既能覆盖API调用的语义边界，又避免盲目生成无效用例。

在80个工具包API的实验中，IntenTest的错误暴露率比基线方法平均提升2.3倍，且仅需1/5的查询量即可达到相同覆盖率。特别值得注意的是，框架展现出良好的迁移能力——用小规模LLM生成的测试用例能有效检测更强目标模型的缺陷，且能自适应跨领域API的演化。实验中的典型案例显示，智能体在处理"将图片亮度提高50%"的变体指令时，会错误调用对比度调整API，这种语义层面的偏差被传统方法完全遗漏，而IntenTest通过参数等价类变异成功捕获。

**最后一句**  
该研究为LLM智能体的意图一致性验证提供了可扩展的方法论，其文档驱动与自适应变异的思路，为构建面向动态API生态的可靠性测试体系开辟了新路径。