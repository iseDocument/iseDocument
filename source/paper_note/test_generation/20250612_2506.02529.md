# 250612_Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs

---
**论文信息**

- **标题**: Automated Web Application Testing: End-to-End Test Case Generation with Large Language Models and Screen Transition Graphs
- **arXiv ID**: 2506.02529
- **作者**: Authors:Nguyen-Khang Le, Quan Minh Bui, Minh Ngoc Nguyen, Hiep Nguyen, Trung Vo, Son T. Luu, Shoshin Nomura, Minh Le Nguyen
- **发表日期**: 2025-06-03T07:08:21+00:00
- **论文链接**: [2506.02529](https://arxiv.org/abs/2506.02529)
- **总结生成时间**: 2025-06-12 17:23:10

---

**一句话概要**  
该研究通过结合大语言模型与屏幕转换图，提出了一种自动化生成Web应用测试用例的新方法，显著提升了导航流程和表单交互的测试覆盖率与鲁棒性。

**主体**  
现代Web应用的动态性和复杂性给可靠性保障带来巨大挑战，尤其在处理多步骤导航流程和条件式表单交互时，传统测试方法往往捉襟见肘。尽管大语言模型（LLMs）在任务自动化方面展现出潜力，但其单独使用时难以准确捕捉页面间的动态跳转逻辑，也无法有效处理表单字段间的条件依赖关系。这一局限性使得自动化测试在覆盖关键用户路径时存在显著缺口。

针对上述问题，作者创新性地将图结构与LLMs深度融合：在导航测试方面，通过屏幕转换图建模页面跳转路径，由LLMs生成覆盖不同用户场景的测试序列；对于表单测试，则构建状态图来刻画字段间的条件约束，并自动转化为可执行的Selenium脚本。这种双轨策略既保留了LLMs的语义理解能力，又通过图结构确保了测试路径的逻辑完备性。特别值得注意的是，研究还构建了首个专注于表单交互评估的综合性数据集，为后续研究提供了基准工具。

实验验证表明，该方法在测试覆盖率和错误检测能力上均优于传统方案。例如，在导航测试中能发现传统方法遗漏的20%边界路径，表单测试的用例生成效率提升近3倍。系统生成的测试脚本成功捕获了多个真实Web应用中的交互缺陷，包括动态加载元素未正确处理、条件字段验证逻辑错误等关键问题。这些成果标志着Web应用测试从手工规则驱动向智能语义驱动的范式转变。

**最后一句**  
该工作为复杂Web系统的质量保障提供了可扩展的自动化框架，其图模型与生成式AI的协同思路或可启发更多软件工程与AI交叉领域的研究。